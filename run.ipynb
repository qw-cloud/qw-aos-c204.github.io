{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Calculating averages...\n",
      "Creating visualization...\n",
      "Visualization saved to: C:\\Users\\Wu996\\Desktop\\Final Project\\output\\rgb_analysis.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def load_data(json_path):\n",
    "    \"\"\"Load and process the planesnet JSON data.\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    images = np.array(data['data'])\n",
    "    labels = np.array(data['labels'])\n",
    "    \n",
    "    # Reshape each image into RGB channels (20x20x3)\n",
    "    n_images = len(images)\n",
    "    images_reshaped = []\n",
    "    for i in range(n_images):\n",
    "        img = images[i]\n",
    "        # Split into RGB channels (each channel is 400 pixels)\n",
    "        r = np.array(img[:400]).reshape(20, 20)\n",
    "        g = np.array(img[400:800]).reshape(20, 20)\n",
    "        b = np.array(img[800:]).reshape(20, 20)\n",
    "        images_reshaped.append(np.dstack((r, g, b)))\n",
    "    \n",
    "    return np.array(images_reshaped), labels\n",
    "\n",
    "def calculate_averages(images, labels):\n",
    "    \"\"\"Calculate average RGB values for plane and no-plane images.\"\"\"\n",
    "    plane_imgs = images[labels == 1]\n",
    "    no_plane_imgs = images[labels == 0]\n",
    "    \n",
    "    plane_avg = np.mean(plane_imgs, axis=0)\n",
    "    no_plane_avg = np.mean(no_plane_imgs, axis=0)\n",
    "    \n",
    "    return plane_avg, no_plane_avg\n",
    "\n",
    "def plot_rgb_averages(plane_avg, no_plane_avg, output_path):\n",
    "    \"\"\"Create the visualization of average RGB values.\"\"\"\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    gs = GridSpec(2, 3, figure=fig)\n",
    "    \n",
    "    titles = ['Average Red', 'Average Green', 'Average Blue']\n",
    "    classes = ['Plane', 'No Plane']\n",
    "    \n",
    "    for i, channel in enumerate(['r', 'g', 'b']):\n",
    "        # Plot for plane class\n",
    "        ax1 = fig.add_subplot(gs[0, i])\n",
    "        im1 = ax1.imshow(plane_avg[:,:,i], cmap='RdYlBu_r', vmin=0, vmax=255)\n",
    "        plt.colorbar(im1, ax=ax1)\n",
    "        ax1.set_title(f'{titles[i]} ({classes[0]})')\n",
    "        \n",
    "        for y in range(0, 20, 5):\n",
    "            for x in range(0, 20, 5):\n",
    "                avg_val = np.mean(plane_avg[y:y+5, x:x+5, i])\n",
    "                ax1.text(x+2.5, y+2.5, f'{avg_val:.1f}', \n",
    "                        ha='center', va='center', fontsize=8)\n",
    "        \n",
    "        ax2 = fig.add_subplot(gs[1, i])\n",
    "        im2 = ax2.imshow(no_plane_avg[:,:,i], cmap='RdYlBu_r', vmin=0, vmax=255)\n",
    "        plt.colorbar(im2, ax=ax2)\n",
    "        ax2.set_title(f'{titles[i]} ({classes[1]})')\n",
    "        \n",
    "        for y in range(0, 20, 5):\n",
    "            for x in range(0, 20, 5):\n",
    "                avg_val = np.mean(no_plane_avg[y:y+5, x:x+5, i])\n",
    "                ax2.text(x+2.5, y+2.5, f'{avg_val:.1f}', \n",
    "                        ha='center', va='center', fontsize=8)\n",
    "    \n",
    "    plt.suptitle('Average RGB Values Over Images (Plane and No Plane)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "\n",
    "    json_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\archive\\planesnet.json'\n",
    "    output_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\output\\rgb_analysis.png'\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    images, labels = load_data(json_path)\n",
    "    \n",
    "    print(\"Calculating averages...\")\n",
    "    plane_avg, no_plane_avg = calculate_averages(images, labels)\n",
    "    \n",
    "    print(\"Creating visualization...\")\n",
    "    plot_rgb_averages(plane_avg, no_plane_avg, output_path)\n",
    "    print(f\"Visualization saved to: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python-3.12.4-amd64\\Lib\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python-3.12.4-amd64\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Results:\n",
      "Training Time: 4.51 seconds\n",
      "Accuracy: 0.9080\n",
      "Precision: 0.8168\n",
      "Recall: 0.8132\n",
      "F1-Score: 0.8150\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Results:\n",
      "Training Time: 7.75 seconds\n",
      "Accuracy: 0.9508\n",
      "Precision: 0.9301\n",
      "Recall: 0.8677\n",
      "F1-Score: 0.8978\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost Results:\n",
      "Training Time: 12.51 seconds\n",
      "Accuracy: 0.9573\n",
      "Precision: 0.9226\n",
      "Recall: 0.9047\n",
      "F1-Score: 0.9136\n",
      "\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 6405, number of negative: 19195\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.166068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 290985\n",
      "[LightGBM] [Info] Number of data points in the train set: 25600, number of used features: 1200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.250195 -> initscore=-1.097571\n",
      "[LightGBM] [Info] Start training from score -1.097571\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Results:\n",
      "Training Time: 4.98 seconds\n",
      "Accuracy: 0.9555\n",
      "Precision: 0.9199\n",
      "Recall: 0.8997\n",
      "F1-Score: 0.9097\n",
      "\n",
      "Training SVM...\n",
      "SVM Results:\n",
      "Training Time: 105.70 seconds\n",
      "Accuracy: 0.9572\n",
      "Precision: 0.9286\n",
      "Recall: 0.8972\n",
      "F1-Score: 0.9126\n",
      "\n",
      "Training KNN...\n",
      "KNN Results:\n",
      "Training Time: 3.15 seconds\n",
      "Accuracy: 0.9475\n",
      "Precision: 0.8785\n",
      "Recall: 0.9160\n",
      "F1-Score: 0.8969\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree Results:\n",
      "Training Time: 28.93 seconds\n",
      "Accuracy: 0.8972\n",
      "Precision: 0.7887\n",
      "Recall: 0.8025\n",
      "F1-Score: 0.7955\n",
      "\n",
      "Training Naive Bayes...\n",
      "Naive Bayes Results:\n",
      "Training Time: 0.43 seconds\n",
      "Accuracy: 0.6398\n",
      "Precision: 0.3931\n",
      "Recall: 0.8188\n",
      "F1-Score: 0.5312\n",
      "\n",
      "Training Simple NN...\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step\n",
      "Simple NN Results:\n",
      "Training Time: 11.01 seconds\n",
      "Accuracy: 0.7508\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python-3.12.4-amd64\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model by accuracy: XGBoost\n",
      "accuracy: 0.9573\n",
      "\n",
      "Best Model by precision: Random Forest\n",
      "precision: 0.9301\n",
      "\n",
      "Best Model by recall: KNN\n",
      "recall: 0.9160\n",
      "\n",
      "Best Model by f1: XGBoost\n",
      "f1: 0.9136\n",
      "\n",
      "Fastest Model: Naive Bayes\n",
      "Training Time: 0.43 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "def load_and_preprocess_data(json_path):\n",
    "    \"\"\"Load and preprocess the planesnet data.\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    X = np.array(data['data'])\n",
    "    y = np.array(data['labels'])\n",
    "    \n",
    "    X = X / 255.0\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def create_simple_nn():\n",
    "    \"\"\"Create a simple neural network.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(100, activation='relu', input_shape=(1200,)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"Calculate various metrics for model evaluation.\"\"\"\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def train_and_evaluate_models(X, y):\n",
    "    \"\"\"Train and evaluate multiple models.\"\"\"\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define models to test\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "        'XGBoost': xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            n_jobs=-1,\n",
    "            tree_method='hist'\n",
    "        ),\n",
    "        'LightGBM': lgb.LGBMClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'SVM': SVC(kernel='rbf'),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Naive Bayes': GaussianNB()\n",
    "    }\n",
    "    \n",
    "    # Add neural network\n",
    "    models['Simple NN'] = create_simple_nn()\n",
    "    \n",
    "    results = {}\n",
    "    training_times = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if name == 'Simple NN':\n",
    "            history = model.fit(X_train, y_train, \n",
    "                              epochs=10, \n",
    "                              batch_size=32, \n",
    "                              validation_split=0.2,\n",
    "                              verbose=0)\n",
    "            y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        metrics = evaluate_model(y_test, y_pred)\n",
    "        results[name] = metrics\n",
    "        training_times[name] = training_time\n",
    "        \n",
    "        print(f\"{name} Results:\")\n",
    "        print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"F1-Score: {metrics['f1']:.4f}\")\n",
    "    \n",
    "    return results, training_times\n",
    "\n",
    "def plot_results(results, training_times, output_path):\n",
    "    \"\"\"Create visualization of model performance.\"\"\"\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    x = np.arange(len(results))\n",
    "    width = 0.2\n",
    "    colors = ['#2ecc71', '#3498db', '#9b59b6', '#e74c3c']\n",
    "    \n",
    "    for i, (metric, color) in enumerate(zip(metrics, colors)):\n",
    "        values = [results[model][metric] for model in results]\n",
    "        plt.bar(x + i*width, values, width, label=metric.capitalize(), color=color, alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.xticks(x + width*1.5, list(results.keys()), rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.bar(training_times.keys(), training_times.values(), color='#f39c12', alpha=0.7)\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Training Time (seconds)')\n",
    "    plt.title('Model Training Times')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Set paths\n",
    "    json_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\archive\\planesnet.json'\n",
    "    output_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\output\\model_comparison_light.png'\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Load data\n",
    "    X, y = load_and_preprocess_data(json_path)\n",
    "    \n",
    "    results, training_times = train_and_evaluate_models(X, y)\n",
    "    \n",
    "    plot_results(results, training_times, output_path)\n",
    "    \n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    for metric in metrics:\n",
    "        best_model = max(results.items(), key=lambda x: x[1][metric])\n",
    "        print(f\"\\nBest Model by {metric}: {best_model[0]}\")\n",
    "        print(f\"{metric}: {best_model[1][metric]:.4f}\")\n",
    "    \n",
    "    fastest_model = min(training_times.items(), key=lambda x: x[1])\n",
    "    print(f\"\\nFastest Model: {fastest_model[0]}\")\n",
    "    print(f\"Training Time: {fastest_model[1]:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN & ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Training Basic CNN...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python-3.12.4-amd64\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8077 - loss: 0.4313 - val_accuracy: 0.9402 - val_loss: 0.1576\n",
      "Epoch 2/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.1554 - val_accuracy: 0.9537 - val_loss: 0.1251\n",
      "Epoch 3/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1319 - val_accuracy: 0.9535 - val_loss: 0.1225\n",
      "Epoch 4/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1242 - val_accuracy: 0.9645 - val_loss: 0.0991\n",
      "Epoch 5/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1006 - val_accuracy: 0.9557 - val_loss: 0.1204\n",
      "Epoch 6/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0952 - val_accuracy: 0.9611 - val_loss: 0.1065\n",
      "Epoch 7/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9702 - loss: 0.0821 - val_accuracy: 0.9678 - val_loss: 0.0926\n",
      "Epoch 8/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9719 - loss: 0.0769 - val_accuracy: 0.9662 - val_loss: 0.0893\n",
      "Epoch 9/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9717 - loss: 0.0750 - val_accuracy: 0.9705 - val_loss: 0.0840\n",
      "Epoch 10/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9706 - loss: 0.0736 - val_accuracy: 0.9711 - val_loss: 0.0859\n",
      "Epoch 11/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0579 - val_accuracy: 0.9744 - val_loss: 0.0770\n",
      "Epoch 12/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.0632 - val_accuracy: 0.9723 - val_loss: 0.0825\n",
      "Epoch 13/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.0556 - val_accuracy: 0.9684 - val_loss: 0.0982\n",
      "Epoch 14/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0590 - val_accuracy: 0.9754 - val_loss: 0.0761\n",
      "Epoch 15/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0444 - val_accuracy: 0.9703 - val_loss: 0.0873\n",
      "Epoch 16/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.0437 - val_accuracy: 0.9746 - val_loss: 0.0806\n",
      "Epoch 17/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0413 - val_accuracy: 0.9777 - val_loss: 0.0674\n",
      "Epoch 18/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0377 - val_accuracy: 0.9766 - val_loss: 0.0751\n",
      "Epoch 19/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9884 - loss: 0.0349 - val_accuracy: 0.9760 - val_loss: 0.0839\n",
      "Epoch 20/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.0335 - val_accuracy: 0.9754 - val_loss: 0.0798\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Basic CNN Results:\n",
      "Accuracy: 0.9702\n",
      "Precision: 0.9239\n",
      "Recall: 0.9592\n",
      "F1-Score: 0.9412\n",
      "\n",
      "Training Deep CNN...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python-3.12.4-amd64\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.8594 - loss: 0.3345 - val_accuracy: 0.8900 - val_loss: 0.2282\n",
      "Epoch 2/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.9467 - loss: 0.1382 - val_accuracy: 0.8881 - val_loss: 0.2924\n",
      "Epoch 3/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.9612 - loss: 0.0953 - val_accuracy: 0.9697 - val_loss: 0.0782\n",
      "Epoch 4/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.9688 - loss: 0.0830 - val_accuracy: 0.9715 - val_loss: 0.0806\n",
      "Epoch 5/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.9748 - loss: 0.0697 - val_accuracy: 0.9367 - val_loss: 0.1695\n",
      "Epoch 6/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.9770 - loss: 0.0615 - val_accuracy: 0.9516 - val_loss: 0.1268\n",
      "Epoch 7/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.9813 - loss: 0.0559 - val_accuracy: 0.9824 - val_loss: 0.0558\n",
      "Epoch 8/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.9808 - loss: 0.0535 - val_accuracy: 0.9535 - val_loss: 0.1634\n",
      "Epoch 9/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.9847 - loss: 0.0433 - val_accuracy: 0.9764 - val_loss: 0.0744\n",
      "Epoch 10/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.9861 - loss: 0.0417 - val_accuracy: 0.9781 - val_loss: 0.0648\n",
      "Epoch 11/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 35ms/step - accuracy: 0.9886 - loss: 0.0356 - val_accuracy: 0.9391 - val_loss: 0.1597\n",
      "Epoch 12/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.9867 - loss: 0.0354 - val_accuracy: 0.9852 - val_loss: 0.0550\n",
      "Epoch 13/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.9880 - loss: 0.0323 - val_accuracy: 0.9764 - val_loss: 0.0718\n",
      "Epoch 14/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.9902 - loss: 0.0275 - val_accuracy: 0.9742 - val_loss: 0.0946\n",
      "Epoch 15/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.9912 - loss: 0.0268 - val_accuracy: 0.9861 - val_loss: 0.0537\n",
      "Epoch 16/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - accuracy: 0.9928 - loss: 0.0208 - val_accuracy: 0.9568 - val_loss: 0.1361\n",
      "Epoch 17/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.9938 - loss: 0.0198 - val_accuracy: 0.9430 - val_loss: 0.2621\n",
      "Epoch 18/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.9915 - loss: 0.0249 - val_accuracy: 0.9838 - val_loss: 0.0588\n",
      "Epoch 19/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.9952 - loss: 0.0139 - val_accuracy: 0.9861 - val_loss: 0.0523\n",
      "Epoch 20/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.9939 - loss: 0.0183 - val_accuracy: 0.8945 - val_loss: 0.3618\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "Deep CNN Results:\n",
      "Accuracy: 0.9020\n",
      "Precision: 0.9979\n",
      "Recall: 0.6082\n",
      "F1-Score: 0.7557\n",
      "\n",
      "Training Custom ResNet...\n",
      "Epoch 1/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 39ms/step - accuracy: 0.8985 - loss: 0.2307 - val_accuracy: 0.8100 - val_loss: 0.5526\n",
      "Epoch 2/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.9625 - loss: 0.0985 - val_accuracy: 0.8463 - val_loss: 0.5143\n",
      "Epoch 3/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 37ms/step - accuracy: 0.9749 - loss: 0.0687 - val_accuracy: 0.9020 - val_loss: 0.2461\n",
      "Epoch 4/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.9797 - loss: 0.0522 - val_accuracy: 0.9756 - val_loss: 0.0644\n",
      "Epoch 5/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - accuracy: 0.9815 - loss: 0.0511 - val_accuracy: 0.9580 - val_loss: 0.1094\n",
      "Epoch 6/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.9866 - loss: 0.0400 - val_accuracy: 0.7730 - val_loss: 1.3028\n",
      "Epoch 7/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 40ms/step - accuracy: 0.9855 - loss: 0.0388 - val_accuracy: 0.9357 - val_loss: 0.1676\n",
      "Epoch 8/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.9883 - loss: 0.0320 - val_accuracy: 0.9723 - val_loss: 0.0925\n",
      "Epoch 9/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.9888 - loss: 0.0320 - val_accuracy: 0.9654 - val_loss: 0.1115\n",
      "Epoch 10/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.9902 - loss: 0.0285 - val_accuracy: 0.7709 - val_loss: 2.1014\n",
      "Epoch 11/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.9917 - loss: 0.0234 - val_accuracy: 0.9795 - val_loss: 0.0712\n",
      "Epoch 12/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.9935 - loss: 0.0182 - val_accuracy: 0.9711 - val_loss: 0.0902\n",
      "Epoch 13/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.9922 - loss: 0.0206 - val_accuracy: 0.9215 - val_loss: 0.2920\n",
      "Epoch 14/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.9941 - loss: 0.0163 - val_accuracy: 0.9637 - val_loss: 0.1225\n",
      "Epoch 15/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.9937 - loss: 0.0168 - val_accuracy: 0.9842 - val_loss: 0.0594\n",
      "Epoch 16/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.9970 - loss: 0.0096 - val_accuracy: 0.9623 - val_loss: 0.1535\n",
      "Epoch 17/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.9952 - loss: 0.0144 - val_accuracy: 0.9820 - val_loss: 0.0580\n",
      "Epoch 18/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.9947 - loss: 0.0122 - val_accuracy: 0.9717 - val_loss: 0.0923\n",
      "Epoch 19/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 40ms/step - accuracy: 0.9934 - loss: 0.0192 - val_accuracy: 0.9732 - val_loss: 0.1168\n",
      "Epoch 20/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.9960 - loss: 0.0126 - val_accuracy: 0.9852 - val_loss: 0.0514\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step\n",
      "Custom ResNet Results:\n",
      "Accuracy: 0.9862\n",
      "Precision: 0.9736\n",
      "Recall: 0.9712\n",
      "F1-Score: 0.9724\n",
      "\n",
      "Best Model: Custom ResNet\n",
      "Best Accuracy: 0.9862\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
    "\n",
    "def load_data(json_path):\n",
    "    \"\"\"Load and preprocess the planesnet data.\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    X = np.array(data['data'])\n",
    "    y = np.array(data['labels'])\n",
    "    \n",
    "    # Reshape images to 20x20x3\n",
    "    n_images = len(X)\n",
    "    X_reshaped = np.zeros((n_images, 20, 20, 3))\n",
    "    for i in range(n_images):\n",
    "        r = X[i][:400].reshape(20, 20)\n",
    "        g = X[i][400:800].reshape(20, 20)\n",
    "        b = X[i][800:].reshape(20, 20)\n",
    "        X_reshaped[i] = np.dstack((r, g, b))\n",
    "    \n",
    "    X_reshaped = X_reshaped / 255.0\n",
    "    \n",
    "    return X_reshaped, y\n",
    "\n",
    "def create_basic_cnn():\n",
    "    \"\"\"Create a basic CNN model.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(20, 20, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model, \"Basic CNN\"\n",
    "\n",
    "def create_deep_cnn():\n",
    "    \"\"\"Create a deeper CNN model.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(20, 20, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model, \"Deep CNN\"\n",
    "\n",
    "def create_original_model():\n",
    "    \"\"\"Create the original model from the paper.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(300, activation='relu', input_shape=(1200,)),\n",
    "        layers.Dense(100, activation='relu'),\n",
    "        layers.Dense(100, activation='relu'),\n",
    "        layers.Dense(100, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model, \"Original Model\"\n",
    "\n",
    "def create_residual_block(x, filters, kernel_size=3):\n",
    "    \"\"\"Create a residual block.\"\"\"\n",
    "    y = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation('relu')(y)\n",
    "    y = layers.Conv2D(filters, kernel_size, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    \n",
    "    if x.shape[-1] != filters:\n",
    "        x = layers.Conv2D(filters, 1, padding='same')(x)\n",
    "    \n",
    "    out = layers.Add()([x, y])\n",
    "    out = layers.Activation('relu')(out)\n",
    "    return out\n",
    "\n",
    "def create_custom_resnet():\n",
    "    \"\"\"Create a custom ResNet-style model.\"\"\"\n",
    "    inputs = layers.Input(shape=(20, 20, 3))\n",
    "    \n",
    "    x = layers.Conv2D(32, 3, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = create_residual_block(x, 32)\n",
    "    x = create_residual_block(x, 32)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    \n",
    "    x = create_residual_block(x, 64)\n",
    "    x = create_residual_block(x, 64)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model, \"Custom ResNet\"\n",
    "\n",
    "def train_and_evaluate_models(X, y, output_path):\n",
    "    \"\"\"Train and evaluate multiple model architectures.\"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model_creators = [\n",
    "        create_basic_cnn,\n",
    "        create_deep_cnn,\n",
    "        create_custom_resnet\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for create_model in model_creators:\n",
    "        model, model_name = create_model()\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=20,\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'name': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'history': history.history\n",
    "        })\n",
    "        \n",
    "        print(f\"{model_name} Results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    plot_results(results, output_path)\n",
    "    \n",
    "    best_model = max(results, key=lambda x: x['accuracy'])\n",
    "    print(f\"\\nBest Model: {best_model['name']}\")\n",
    "    print(f\"Best Accuracy: {best_model['accuracy']:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_results(results, output_path):\n",
    "    \"\"\"Create visualization of model performance.\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    x = np.arange(len(results))\n",
    "    width = 0.2\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        values = [r[metric] for r in results]\n",
    "        plt.bar(x + i*width, values, width, label=metric.capitalize())\n",
    "    \n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.xticks(x + width*1.5, [r['name'] for r in results])\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    for result in results:\n",
    "        plt.plot(result['history']['val_accuracy'], label=f\"{result['name']}\")\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title('Training History')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Set paths\n",
    "    json_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\archive\\planesnet.json'\n",
    "    output_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\output\\model_comparison.png'\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Load data\n",
    "    X, y = load_data(json_path)\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    results = train_and_evaluate_models(X, y, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Epoch 1/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.8910 - loss: 0.2509 - val_accuracy: 0.8846 - val_loss: 0.2884\n",
      "Epoch 2/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.9614 - loss: 0.0999 - val_accuracy: 0.7777 - val_loss: 0.7223\n",
      "Epoch 3/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.9759 - loss: 0.0674 - val_accuracy: 0.9686 - val_loss: 0.0882\n",
      "Epoch 4/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.9784 - loss: 0.0613 - val_accuracy: 0.9760 - val_loss: 0.0642\n",
      "Epoch 5/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 40ms/step - accuracy: 0.9826 - loss: 0.0487 - val_accuracy: 0.7563 - val_loss: 2.5571\n",
      "Epoch 6/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.9832 - loss: 0.0467 - val_accuracy: 0.9703 - val_loss: 0.0878\n",
      "Epoch 7/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 49ms/step - accuracy: 0.9867 - loss: 0.0381 - val_accuracy: 0.8053 - val_loss: 0.8472\n",
      "Epoch 8/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 49ms/step - accuracy: 0.9879 - loss: 0.0342 - val_accuracy: 0.9553 - val_loss: 0.1391\n",
      "Epoch 9/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.9885 - loss: 0.0341 - val_accuracy: 0.9344 - val_loss: 0.2236\n",
      "Epoch 10/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.9919 - loss: 0.0239 - val_accuracy: 0.9777 - val_loss: 0.0626\n",
      "Epoch 11/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.9882 - loss: 0.0315 - val_accuracy: 0.9807 - val_loss: 0.0601\n",
      "Epoch 12/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.9916 - loss: 0.0222 - val_accuracy: 0.9777 - val_loss: 0.0624\n",
      "Epoch 13/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.9929 - loss: 0.0194 - val_accuracy: 0.9576 - val_loss: 0.1261\n",
      "Epoch 14/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 40ms/step - accuracy: 0.9939 - loss: 0.0193 - val_accuracy: 0.9301 - val_loss: 0.2215\n",
      "Epoch 15/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.9956 - loss: 0.0126 - val_accuracy: 0.9484 - val_loss: 0.1780\n",
      "Epoch 16/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.9937 - loss: 0.0194 - val_accuracy: 0.9582 - val_loss: 0.1364\n",
      "Epoch 17/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.9950 - loss: 0.0128 - val_accuracy: 0.8322 - val_loss: 0.8716\n",
      "Epoch 18/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.9936 - loss: 0.0158 - val_accuracy: 0.9838 - val_loss: 0.0557\n",
      "Epoch 19/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.9948 - loss: 0.0145 - val_accuracy: 0.9783 - val_loss: 0.0772\n",
      "Epoch 20/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.9960 - loss: 0.0129 - val_accuracy: 0.9744 - val_loss: 0.0763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step\n",
      "Creating visualizations...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "Model and visualizations saved to C:\\Users\\Wu996\\Desktop\\Final Project\\output\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, average_precision_score\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "from sklearn.metrics import auc\n",
    "import shap\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "def create_residual_block(x, filters, kernel_size=3):\n",
    "    \"\"\"Create a residual block.\"\"\"\n",
    "    y = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation('relu')(y)\n",
    "    y = layers.Conv2D(filters, kernel_size, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    \n",
    "    if x.shape[-1] != filters:\n",
    "        x = layers.Conv2D(filters, 1, padding='same')(x)\n",
    "    \n",
    "    out = layers.Add()([x, y])\n",
    "    out = layers.Activation('relu')(out)\n",
    "    return out\n",
    "\n",
    "def create_custom_resnet():\n",
    "    \"\"\"Create the Custom ResNet model.\"\"\"\n",
    "    inputs = layers.Input(shape=(20, 20, 3))\n",
    "    \n",
    "    x = layers.Conv2D(32, 3, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = create_residual_block(x, 32)\n",
    "    x = create_residual_block(x, 32)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    \n",
    "    x = create_residual_block(x, 64)\n",
    "    x = create_residual_block(x, 64)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def load_data(json_path):\n",
    "    \"\"\"Load and preprocess the planesnet data.\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(data['data'])\n",
    "    y = np.array(data['labels'])\n",
    "    \n",
    "    # Reshape images to 20x20x3\n",
    "    n_images = len(X)\n",
    "    X_reshaped = np.zeros((n_images, 20, 20, 3))\n",
    "    for i in range(n_images):\n",
    "        r = X[i][:400].reshape(20, 20)\n",
    "        g = X[i][400:800].reshape(20, 20)\n",
    "        b = X[i][800:].reshape(20, 20)\n",
    "        X_reshaped[i] = np.dstack((r, g, b))\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    X_reshaped = X_reshaped / 255.0\n",
    "    \n",
    "    return X_reshaped, y\n",
    "\n",
    "def plot_training_history(history, output_path):\n",
    "    \"\"\"Create an interactive training history plot.\"\"\"\n",
    "    fig = make_subplots(rows=1, cols=2, \n",
    "                       subplot_titles=('Model Accuracy', 'Model Loss'))\n",
    "    \n",
    "    # Accuracy subplot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=history.history['accuracy'], name=\"Training Accuracy\",\n",
    "                  line=dict(color='royalblue', width=2)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=history.history['val_accuracy'], name=\"Validation Accuracy\",\n",
    "                  line=dict(color='lightblue', width=2, dash='dash')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Loss subplot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=history.history['loss'], name=\"Training Loss\",\n",
    "                  line=dict(color='firebrick', width=2)),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=history.history['val_loss'], name=\"Validation Loss\",\n",
    "                  line=dict(color='lightcoral', width=2, dash='dash')),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=500, width=1000, title_text=\"Training History\")\n",
    "    fig.write_html(os.path.join(output_path, 'training_history.html'))\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, output_path):\n",
    "    \"\"\"Create an enhanced confusion matrix visualization.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate percentages\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # Create annotation text\n",
    "    annotations = []\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            annotations.append(\n",
    "                f'Count: {cm[i, j]}<br>Percentage: {cm_percent[i, j]:.1f}%'\n",
    "            )\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=cm,\n",
    "        x=['Predicted Negative', 'Predicted Positive'],\n",
    "        y=['Actual Negative', 'Actual Positive'],\n",
    "        text=annotations,\n",
    "        texttemplate=\"%{text}\",\n",
    "        textfont={\"size\": 12},\n",
    "        colorscale='RdBu',\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Confusion Matrix',\n",
    "        xaxis_title='Predicted Label',\n",
    "        yaxis_title='True Label',\n",
    "        width=800,\n",
    "        height=800\n",
    "    )\n",
    "    \n",
    "    fig.write_html(os.path.join(output_path, 'confusion_matrix.html'))\n",
    "\n",
    "def plot_roc_pr_curves(y_true, y_pred_proba, output_path):\n",
    "    \"\"\"Create interactive ROC and PR curves.\"\"\"\n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Calculate PR curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    pr_auc = average_precision_score(y_true, y_pred_proba)\n",
    "    \n",
    "    # Create subplot\n",
    "    fig = make_subplots(rows=1, cols=2, \n",
    "                       subplot_titles=('ROC Curve', 'Precision-Recall Curve'))\n",
    "    \n",
    "    # ROC curve\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=fpr, y=tpr, name=f'ROC Curve (AUC = {roc_auc:.3f})',\n",
    "                  fill='tozeroy', line=dict(color='royalblue', width=2)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[0, 1], y=[0, 1], name='Random Classifier',\n",
    "                  line=dict(color='gray', dash='dash')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # PR curve\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=recall, y=precision, \n",
    "                  name=f'PR Curve (AP = {pr_auc:.3f})',\n",
    "                  fill='tozeroy', line=dict(color='firebrick', width=2)),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=500, width=1000,\n",
    "        showlegend=True,\n",
    "        title_text=\"Model Performance Curves\"\n",
    "    )\n",
    "    \n",
    "    fig.write_html(os.path.join(output_path, 'performance_curves.html'))\n",
    "\n",
    "def visualize_feature_maps(model, X_sample, output_path):\n",
    "    \"\"\"Visualize feature maps from different layers.\"\"\"\n",
    "    # Get feature maps from intermediate layers\n",
    "    layer_outputs = [layer.output for layer in model.layers if isinstance(layer, layers.Conv2D)]\n",
    "    feature_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    \n",
    "    # Get feature maps for a sample image\n",
    "    feature_maps = feature_model.predict(X_sample[np.newaxis, ...])\n",
    "    \n",
    "    # Create visualization for each conv layer\n",
    "    for layer_idx, feature_map in enumerate(feature_maps):\n",
    "        # Create grid of feature maps\n",
    "        n_features = min(8, feature_map.shape[-1])  # Display up to 8 features\n",
    "        size = feature_map.shape[1]\n",
    "        display_grid = np.zeros((size * 2, size * 4))\n",
    "        \n",
    "        for i in range(2):\n",
    "            for j in range(4):\n",
    "                if i * 4 + j < n_features:\n",
    "                    display_grid[i * size:(i + 1) * size, \n",
    "                               j * size:(j + 1) * size] = feature_map[0, :, :, i * 4 + j]\n",
    "        \n",
    "        # Normalize the grid\n",
    "        display_grid = (display_grid - display_grid.min()) / (display_grid.max() - display_grid.min())\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.title(f'Feature Maps - Conv Layer {layer_idx + 1}')\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "        plt.colorbar()\n",
    "        plt.savefig(os.path.join(output_path, f'feature_maps_layer_{layer_idx + 1}.png'))\n",
    "        plt.close()\n",
    "\n",
    "def main():\n",
    "    # Set paths\n",
    "    json_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\archive\\planesnet.json'\n",
    "    output_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\output'\n",
    "    model_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\models\\custom_resnet.h5'\n",
    "    \n",
    "    # Create output directories\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    X, y = load_data(json_path)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create and train model\n",
    "    model = create_custom_resnet()\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                       epochs=20,\n",
    "                       batch_size=32,\n",
    "                       validation_split=0.2,\n",
    "                       verbose=1)\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    # Create visualizations\n",
    "    print(\"Creating visualizations...\")\n",
    "    \n",
    "    # 1. Training history\n",
    "    plot_training_history(history, output_path)\n",
    "    \n",
    "    # 2. Confusion matrix\n",
    "    plot_confusion_matrix(y_test, y_pred, output_path)\n",
    "    \n",
    "    # 3. ROC and PR curves\n",
    "    plot_roc_pr_curves(y_test, y_pred_proba, output_path)\n",
    "    \n",
    "    # 4. Feature maps visualization\n",
    "    visualize_feature_maps(model, X_test[0], output_path)\n",
    "    \n",
    "    print(f\"Model and visualizations saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Generating predictions...\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step\n",
      "Creating confusion matrix visualization...\n",
      "Visualization saved to: C:\\Users\\Wu996\\Desktop\\Final Project\\output\\confusion_matrix_enhanced.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_and_preprocess_data(json_path):\n",
    "    \"\"\"Load and preprocess the planesnet data.\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(data['data'])\n",
    "    y = np.array(data['labels'])\n",
    "    \n",
    "    # Reshape images to 20x20x3\n",
    "    n_images = len(X)\n",
    "    X_reshaped = np.zeros((n_images, 20, 20, 3))\n",
    "    for i in range(n_images):\n",
    "        r = X[i][:400].reshape(20, 20)\n",
    "        g = X[i][400:800].reshape(20, 20)\n",
    "        b = X[i][800:].reshape(20, 20)\n",
    "        X_reshaped[i] = np.dstack((r, g, b))\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    X_reshaped = X_reshaped / 255.0\n",
    "    \n",
    "    return X_reshaped, y\n",
    "\n",
    "def create_enhanced_confusion_matrix(y_true, y_pred, output_path):\n",
    "    \"\"\"Create an enhanced confusion matrix visualization with direct number display.\"\"\"\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate percentages\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # Create figure and axes\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Predicted\\nNegative', 'Predicted\\nPositive'],\n",
    "                yticklabels=['Actual\\nNegative', 'Actual\\nPositive'])\n",
    "    \n",
    "    # Add percentage values\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j + 0.5, i + 0.7, f'({cm_percent[i, j]:.1f}%)',\n",
    "                    ha='center', va='center',\n",
    "                    color='black' if cm_percent[i, j] < 70 else 'white')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Confusion Matrix', pad=20, fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Add a custom legend/explanation\n",
    "    plt.figtext(0.15, -0.05, \n",
    "                'Format: count (percentage)\\nPercentages calculated row-wise (per actual class)',\n",
    "                ha='left', fontsize=10, style='italic')\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Set paths\n",
    "    json_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\archive\\planesnet.json'\n",
    "    model_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\models\\custom_resnet.h5'\n",
    "    output_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\output\\confusion_matrix_enhanced.png'\n",
    "    \n",
    "    # Create output directory if doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Load data\n",
    "    X, y = load_and_preprocess_data(json_path)\n",
    "    \n",
    "    # Load the saved model\n",
    "    print(\"Loading model...\")\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Generate predictions\n",
    "    print(\"Generating predictions...\")\n",
    "    y_pred_proba = model.predict(X)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    # Create and save confusion matrix visualization\n",
    "    print(\"Creating confusion matrix visualization...\")\n",
    "    create_enhanced_confusion_matrix(y, y_pred, output_path)\n",
    "    print(f\"Visualization saved to: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained Basic CNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Custom ResNet...\n",
      "\n",
      "Processing scene_1.png...\n",
      "Running Basic CNN detection...\n",
      "Running Custom ResNet detection...\n",
      "\n",
      "Processing scene_2.png...\n",
      "Running Basic CNN detection...\n",
      "Running Custom ResNet detection...\n",
      "\n",
      "Processing scene_3.png...\n",
      "Running Basic CNN detection...\n",
      "Running Custom ResNet detection...\n",
      "\n",
      "Processing scene_4.png...\n",
      "Running Basic CNN detection...\n",
      "Running Custom ResNet detection...\n",
      "\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_basic_cnn():\n",
    "    \"\"\"Create a basic CNN model.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(20, 20, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def load_and_preprocess_data(json_path):\n",
    "    \"\"\"Load and preprocess the planesnet data.\"\"\"\n",
    "    print(\"Loading training data...\")\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    X = np.array(data['data'])\n",
    "    y = np.array(data['labels'])\n",
    "    \n",
    "    # Reshape images to 20x20x3\n",
    "    n_images = len(X)\n",
    "    X_reshaped = np.zeros((n_images, 20, 20, 3))\n",
    "    for i in range(n_images):\n",
    "        r = X[i][:400].reshape(20, 20)\n",
    "        g = X[i][400:800].reshape(20, 20)\n",
    "        b = X[i][800:].reshape(20, 20)\n",
    "        X_reshaped[i] = np.dstack((r, g, b))\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    X_reshaped = X_reshaped / 255.0\n",
    "    \n",
    "    return X_reshaped, y\n",
    "\n",
    "def batch_process_scene(model, scene, batch_size=64, step_size=5): \n",
    "    \"\"\"Process scene in batches for faster detection.\"\"\"\n",
    "    height, width = scene.shape[:2]\n",
    "    windows = []\n",
    "    positions = []\n",
    "    \n",
    "    # Extract all windows and their positions with smaller step size\n",
    "    for y in range(0, height - 20, step_size):\n",
    "        for x in range(0, width - 20, step_size):\n",
    "            window = scene[y:y+20, x:x+20]\n",
    "            if window.shape[:2] == (20, 20):\n",
    "                windows.append(window)\n",
    "                positions.append((x, y))\n",
    "    \n",
    "    # Convert to numpy array and normalize\n",
    "    windows = np.array(windows).astype('float32') / 255.0\n",
    "    \n",
    "    # Batch predict\n",
    "    detections = []\n",
    "    for i in range(0, len(windows), batch_size):\n",
    "        batch = windows[i:i + batch_size]\n",
    "        predictions = model.predict(batch, verbose=0)\n",
    "        \n",
    "        # Add detections above threshold\n",
    "        for j, pred in enumerate(predictions):\n",
    "            if pred[0] > 0.3: \n",
    "                x, y = positions[i + j]\n",
    "                detections.append((x, y, float(pred[0])))\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def non_max_suppression(boxes, overlap_thresh=0.2): \n",
    "    \"\"\"Apply non-maximum suppression.\"\"\"\n",
    "    if not boxes:\n",
    "        return []\n",
    "    \n",
    "    boxes = np.array(boxes)\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = x1 + 20\n",
    "    y2 = y1 + 20\n",
    "    scores = boxes[:, 2]\n",
    "    \n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    order = scores.argsort()[::-1]\n",
    "    \n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        \n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "        \n",
    "        w = np.maximum(0.0, xx2 - xx1)\n",
    "        h = np.maximum(0.0, yy2 - yy1)\n",
    "        overlap = (w * h) / areas[order[1:]]\n",
    "        \n",
    "        inds = np.where(overlap <= overlap_thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "    \n",
    "    return boxes[keep].tolist()\n",
    "\n",
    "def visualize_results(scene, detections, title, save_path):\n",
    "    \"\"\"Visualize detection results.\"\"\"\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    plt.imshow(scene)\n",
    "    \n",
    "    # Sort detections by confidence\n",
    "    detections = sorted(detections, key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # Draw detection boxes with different colors based on confidence\n",
    "    for x, y, conf in detections:\n",
    "        # Color mapping based on confidence (red for high confidence, yellow for lower)\n",
    "        color = plt.cm.RdYlBu_r(conf)\n",
    "        rect = plt.Rectangle((x, y), 20, 20, fill=False, color=color, linewidth=2)\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.text(x, y-5, f'{conf:.2f}', color='black', \n",
    "                bbox=dict(facecolor='white', alpha=0.7))\n",
    "    \n",
    "    plt.title(f'{title}\\nTotal Detections: {len(detections)}')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Set paths\n",
    "    json_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\archive\\planesnet.json'\n",
    "    scenes_dir = r'C:\\Users\\Wu996\\Desktop\\Final Project\\archive\\scenes\\scenes'\n",
    "    output_dir = r'C:\\Users\\Wu996\\Desktop\\Final Project\\output\\scene_verification'\n",
    "    model_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\models\\custom_resnet.h5'\n",
    "    basic_cnn_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\models\\basic_cnn.h5'\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(basic_cnn_path), exist_ok=True)\n",
    "    \n",
    "    X_train, y_train = load_and_preprocess_data(json_path)\n",
    "    \n",
    "    if not os.path.exists(basic_cnn_path):\n",
    "        print(\"Training Basic CNN...\")\n",
    "        basic_cnn = create_basic_cnn()\n",
    "        basic_cnn.compile(optimizer='adam',\n",
    "                         loss='binary_crossentropy',\n",
    "                         metrics=['accuracy'])\n",
    "        \n",
    "        basic_cnn.fit(X_train, y_train,\n",
    "                     epochs=20,\n",
    "                     batch_size=40,\n",
    "                     validation_split=0.2,\n",
    "                     verbose=1)\n",
    "        \n",
    "        basic_cnn.save(basic_cnn_path)\n",
    "    else:\n",
    "        print(\"Loading trained Basic CNN...\")\n",
    "        basic_cnn = load_model(basic_cnn_path)\n",
    "    \n",
    "    print(\"Loading Custom ResNet...\")\n",
    "    custom_resnet = load_model(model_path)\n",
    "    \n",
    "    scene_files = [f for f in os.listdir(scenes_dir) if f.endswith('.png')]\n",
    "    \n",
    "    for scene_file in scene_files:\n",
    "        print(f\"\\nProcessing {scene_file}...\")\n",
    "        scene_path = os.path.join(scenes_dir, scene_file)\n",
    "        \n",
    "        scene = cv2.imread(scene_path)\n",
    "        scene = cv2.cvtColor(scene, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        for model, model_name in [(basic_cnn, \"Basic CNN\"), (custom_resnet, \"Custom ResNet\")]:\n",
    "            print(f\"Running {model_name} detection...\")\n",
    "            detections = batch_process_scene(model, scene, step_size=5) \n",
    "            detections = non_max_suppression(detections, overlap_thresh=0.2) \n",
    "            \n",
    "            visualize_results(\n",
    "                scene,\n",
    "                detections,\n",
    "                f\"{model_name} Detection - {scene_file}\",\n",
    "                os.path.join(output_dir, f'{model_name.lower().replace(\" \", \"_\")}_{scene_file}')\n",
    "            )\n",
    "    \n",
    "    print(\"\\nProcessing complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scenes_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained Basic CNN...\n",
      "Loading Custom ResNet...\n",
      "\n",
      "Processing images.jpg...\n",
      "Running Basic CNN detection...\n",
      "Running Custom ResNet detection...\n",
      "\n",
      "Processing images1.jpg...\n",
      "Running Basic CNN detection...\n",
      "Running Custom ResNet detection...\n",
      "\n",
      "Processing images2.jpg...\n",
      "Running Basic CNN detection...\n",
      "Running Custom ResNet detection...\n",
      "\n",
      "Processing images3.jpg...\n",
      "Running Basic CNN detection...\n",
      "Running Custom ResNet detection...\n",
      "\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_basic_cnn():\n",
    "    \"\"\"Create a basic CNN model.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(20, 20, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def load_and_preprocess_data(json_path):\n",
    "    \"\"\"Load and preprocess the planesnet data.\"\"\"\n",
    "    print(\"Loading training data...\")\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    X = np.array(data['data'])\n",
    "    y = np.array(data['labels'])\n",
    "    \n",
    "    # Reshape images to 20x20x3\n",
    "    n_images = len(X)\n",
    "    X_reshaped = np.zeros((n_images, 20, 20, 3))\n",
    "    for i in range(n_images):\n",
    "        r = X[i][:400].reshape(20, 20)\n",
    "        g = X[i][400:800].reshape(20, 20)\n",
    "        b = X[i][800:].reshape(20, 20)\n",
    "        X_reshaped[i] = np.dstack((r, g, b))\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    X_reshaped = X_reshaped / 255.0\n",
    "    \n",
    "    return X_reshaped, y\n",
    "\n",
    "def batch_process_scene(model, scene, batch_size=64, step_size=2):  #step_size!\n",
    "    \"\"\"Process scene in batches for faster detection.\"\"\"\n",
    "    height, width = scene.shape[:2]\n",
    "    windows = []\n",
    "    positions = []\n",
    "    \n",
    "    # Extract all windows and their positions with smaller step size\n",
    "    for y in range(0, height - 20, step_size):\n",
    "        for x in range(0, width - 20, step_size):\n",
    "            window = scene[y:y+20, x:x+20]\n",
    "            if window.shape[:2] == (20, 20):\n",
    "                windows.append(window)\n",
    "                positions.append((x, y))\n",
    "    \n",
    "    # Convert to numpy array and normalize\n",
    "    windows = np.array(windows).astype('float32') / 255.0\n",
    "    \n",
    "    # Batch predict\n",
    "    detections = []\n",
    "    for i in range(0, len(windows), batch_size):\n",
    "        batch = windows[i:i + batch_size]\n",
    "        predictions = model.predict(batch, verbose=0)\n",
    "        \n",
    "        # Add detections above threshold\n",
    "        for j, pred in enumerate(predictions):\n",
    "            if pred[0] > 0.3: \n",
    "                x, y = positions[i + j]\n",
    "                detections.append((x, y, float(pred[0])))\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def non_max_suppression(boxes, overlap_thresh=0.2): \n",
    "    \"\"\"Apply non-maximum suppression.\"\"\"\n",
    "    if not boxes:\n",
    "        return []\n",
    "    \n",
    "    boxes = np.array(boxes)\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = x1 + 20\n",
    "    y2 = y1 + 20\n",
    "    scores = boxes[:, 2]\n",
    "    \n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    order = scores.argsort()[::-1]\n",
    "    \n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        \n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "        \n",
    "        w = np.maximum(0.0, xx2 - xx1)\n",
    "        h = np.maximum(0.0, yy2 - yy1)\n",
    "        overlap = (w * h) / areas[order[1:]]\n",
    "        \n",
    "        inds = np.where(overlap <= overlap_thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "    \n",
    "    return boxes[keep].tolist()\n",
    "\n",
    "def visualize_results(scene, detections, title, save_path):\n",
    "    \"\"\"Visualize detection results.\"\"\"\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    plt.imshow(scene)\n",
    "    \n",
    "    # Sort detections by confidence\n",
    "    detections = sorted(detections, key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # Draw detection boxes with different colors based on confidence\n",
    "    for x, y, conf in detections:\n",
    "        # Color mapping based on confidence (red for high confidence, yellow for lower)\n",
    "        color = plt.cm.RdYlBu_r(conf)\n",
    "        rect = plt.Rectangle((x, y), 20, 20, fill=False, color=color, linewidth=2)\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.text(x, y-5, f'{conf:.2f}', color='black', \n",
    "                bbox=dict(facecolor='white', alpha=0.7))\n",
    "    \n",
    "    plt.title(f'{title}\\nTotal Detections: {len(detections)}')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Set paths\n",
    "    json_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\archive\\planesnet.json'\n",
    "    scenes_dir = r'C:\\Users\\Wu996\\Desktop\\Final Project\\archive\\scenes\\scenes_1'\n",
    "    output_dir = r'C:\\Users\\Wu996\\Desktop\\Final Project\\output\\scene_verification_1'\n",
    "    model_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\models\\custom_resnet.h5'\n",
    "    basic_cnn_path = r'C:\\Users\\Wu996\\Desktop\\Final Project\\models\\basic_cnn.h5'\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(basic_cnn_path), exist_ok=True)\n",
    "    \n",
    "    X_train, y_train = load_and_preprocess_data(json_path)\n",
    "    \n",
    "    if not os.path.exists(basic_cnn_path):\n",
    "        print(\"Training Basic CNN...\")\n",
    "        basic_cnn = create_basic_cnn()\n",
    "        basic_cnn.compile(optimizer='adam',\n",
    "                         loss='binary_crossentropy',\n",
    "                         metrics=['accuracy'])\n",
    "        \n",
    "        basic_cnn.fit(X_train, y_train,\n",
    "                     epochs=20,\n",
    "                     batch_size=40,\n",
    "                     validation_split=0.2,\n",
    "                     verbose=1)\n",
    "        \n",
    "        basic_cnn.save(basic_cnn_path)\n",
    "    else:\n",
    "        print(\"Loading trained Basic CNN...\")\n",
    "        basic_cnn = load_model(basic_cnn_path)\n",
    "    \n",
    "    print(\"Loading Custom ResNet...\")\n",
    "    custom_resnet = load_model(model_path)\n",
    "    \n",
    "    scene_files = [f for f in os.listdir(scenes_dir) if f.endswith('.jpg')]\n",
    "    \n",
    "    for scene_file in scene_files:\n",
    "        print(f\"\\nProcessing {scene_file}...\")\n",
    "        scene_path = os.path.join(scenes_dir, scene_file)\n",
    "        \n",
    "        scene = cv2.imread(scene_path)\n",
    "        scene = cv2.cvtColor(scene, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        for model, model_name in [(basic_cnn, \"Basic CNN\"), (custom_resnet, \"Custom ResNet\")]:\n",
    "            print(f\"Running {model_name} detection...\")\n",
    "            detections = batch_process_scene(model, scene, step_size=5) \n",
    "            detections = non_max_suppression(detections, overlap_thresh=0.2) \n",
    "            \n",
    "            visualize_results(\n",
    "                scene,\n",
    "                detections,\n",
    "                f\"{model_name} Detection - {scene_file}\",\n",
    "                os.path.join(output_dir, f'{model_name.lower().replace(\" \", \"_\")}_{scene_file}')\n",
    "            )\n",
    "    \n",
    "    print(\"\\nProcessing complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
